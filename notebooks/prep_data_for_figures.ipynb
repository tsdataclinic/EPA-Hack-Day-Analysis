{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T14:20:28.955135Z",
     "iopub.status.busy": "2023-06-30T14:20:28.954845Z",
     "iopub.status.idle": "2023-06-30T14:20:40.564967Z",
     "shell.execute_reply": "2023-06-30T14:20:40.563933Z",
     "shell.execute_reply.started": "2023-06-30T14:20:28.955075Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "import io\n",
    "from shapely.geometry import Point, Polygon\n",
    "from shapely.ops import unary_union\n",
    "import pathlib\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "# Use your own path here\n",
    "os.chdir(\"/Users/canyonfoot/Documents/python_proj/EPA-Hack-Day-Analysis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T14:20:40.569660Z",
     "iopub.status.busy": "2023-06-30T14:20:40.569364Z",
     "iopub.status.idle": "2023-06-30T14:24:54.776956Z",
     "shell.execute_reply": "2023-06-30T14:24:54.776118Z",
     "shell.execute_reply.started": "2023-06-30T14:20:40.569630Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gdf_urban_all = gpd.read_file(\"https://www2.census.gov/geo/tiger/TIGER_RD18/LAYER/UAC20/tl_rd22_us_uac20.zip\").rename(columns = {\"NAME20\": \"UA_NAME\"})[['UA_NAME','geometry']].to_crs(2263)\n",
    "gdf_tract = gpd.read_file(\"data/processed/US_tract_census.geojson\").to_crs(2263)\n",
    "RMP_facilities = gpd.read_file(\"data/processed/facilities_geo.geojson\").to_crs(2263)\n",
    "UA_stats = pd.read_csv(\"data/processed/urban_area_statistics.csv\").query(\"facility_count >= 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_UAs = gdf_urban_all[gdf_urban_all.UA_NAME.isin(UA_stats.UA_NAME)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T14:24:54.823464Z",
     "iopub.status.busy": "2023-06-30T14:24:54.822796Z",
     "iopub.status.idle": "2023-06-30T14:24:55.162150Z",
     "shell.execute_reply": "2023-06-30T14:24:55.161417Z",
     "shell.execute_reply.started": "2023-06-30T14:24:54.823440Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We need these columns\n",
    "gdf_tract[\"area\"] = gdf_tract.area\n",
    "gdf_tract[\"GEOID\"] = gdf_tract[\"STATE\"] + gdf_tract[\"COUNTY\"] + gdf_tract[\"TRACT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T14:24:55.166616Z",
     "iopub.status.busy": "2023-06-30T14:24:55.165866Z",
     "iopub.status.idle": "2023-06-30T14:24:55.170045Z",
     "shell.execute_reply": "2023-06-30T14:24:55.169412Z",
     "shell.execute_reply.started": "2023-06-30T14:24:55.166591Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "AREAL_WEIGHT_COLUMNS = [\"total_pop\", \"pop_in_poverty\", \"white_pop\", 'black_pop', 'asian_pop',\n",
    "       'hispanic_pop', 'native_american_pop', 'two_or_more_pop',\n",
    "       'total_households', 'owner_households', 'renter_households']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T14:24:55.174000Z",
     "iopub.status.busy": "2023-06-30T14:24:55.173314Z",
     "iopub.status.idle": "2023-06-30T14:24:55.199554Z",
     "shell.execute_reply": "2023-06-30T14:24:55.198945Z",
     "shell.execute_reply.started": "2023-06-30T14:24:55.173962Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_rmp_zones(UA_tracts, RMP_facilities, buffer_miles):\n",
    "    UA_facilities = RMP_facilities.overlay(UA_tracts, keep_geom_type=False)\n",
    "    UA_facilities = UA_facilities.set_geometry(UA_facilities.buffer(5280 * buffer_miles))\n",
    "    \n",
    "    geo = unary_union(UA_facilities.geometry)\n",
    "\n",
    "    return(gpd.GeoDataFrame(geometry = [geo], crs = \"epsg:2263\"))\n",
    "\n",
    "def read_water_file(url):\n",
    "    # Accesses and reads water file from url\n",
    "    session = requests.Session()\n",
    "    response = session.get(url)\n",
    "    assert response.status_code == 200\n",
    "\n",
    "    zipfile_io = io.BytesIO(response.content)\n",
    "\n",
    "    zip = zipfile.ZipFile(zipfile_io)\n",
    "    zip.extractall(\"water_tmp\")\n",
    "\n",
    "    for file in os.listdir(\"water_tmp\"):\n",
    "        if file.endswith('.shp'):\n",
    "            shapefile_name = file\n",
    "            break\n",
    "    \n",
    "    gdf = gpd.read_file(\"water_tmp/\" + shapefile_name)\n",
    "\n",
    "    for file in os.listdir(\"water_tmp\"):\n",
    "        os.remove(\"water_tmp/\" + file)\n",
    "    os.rmdir(\"water_tmp\")\n",
    "    \n",
    "    return(gdf)\n",
    "\n",
    "def get_water(UA_tracts, threshold = 10000):\n",
    "    # Downloads and concatenates water files\n",
    "    distinct_counties = UA_tracts.GEOID.str.slice(0,5).unique()\n",
    "    gdfs = []\n",
    "\n",
    "    for county in distinct_counties:\n",
    "        url = \"https://www2.census.gov/geo/tiger/TIGER2020/AREAWATER/tl_2020_\" + county + \"_areawater.zip\"\n",
    "        temp_gdf = read_water_file(url)\n",
    "        gdfs.append(temp_gdf) \n",
    "    \n",
    "    gdf = gpd.GeoDataFrame(pd.concat(gdfs))\n",
    "    gdf = gdf.set_geometry(\"geometry\").to_crs(2263)\n",
    "\n",
    "    if threshold:\n",
    "        gdf = gdf.query(\"AWATER > @threshold\")\n",
    "\n",
    "    return gdf\n",
    "\n",
    "def remove_water_from_tracts(UA_tracts):\n",
    "    # Drops water from tract geometry\n",
    "    water = get_water(UA_tracts)\n",
    "    unified_water = water.geometry.unary_union\n",
    "    UA_geom_without_water = UA_tracts.geometry.apply(lambda tract: tract.difference(unified_water))\n",
    "\n",
    "    return UA_tracts.set_geometry(UA_geom_without_water)\n",
    "\n",
    "def get_UA_tracts(urban_area_name: str, tracts: gpd.GeoDataFrame, UA_geo: gpd.GeoDataFrame, areal_weight_columns = AREAL_WEIGHT_COLUMNS):\n",
    "    # Intersects census tracts with urban area geometry. Recalculates using weights where overlap is incomplete.\n",
    "    UA = UA_geo.query(\"UA_NAME == @urban_area_name\")\n",
    "    UA_tracts = UA.overlay(tracts, how=\"intersection\", keep_geom_type=False)\n",
    "    UA_tracts = remove_water_from_tracts(UA_tracts)\n",
    "    UA_tracts[\"UA_area\"] = UA_tracts.area\n",
    "    UA_tracts[\"areal_weight\"] = UA_tracts[\"UA_area\"] / UA_tracts[\"area\"]\n",
    "    UA_tracts[areal_weight_columns] = round(UA_tracts[areal_weight_columns].apply(lambda x: x*UA_tracts[\"areal_weight\"]))\n",
    "    UA_tracts = UA_tracts.query(\"total_pop > 50\")\n",
    "    UA_tracts = UA_tracts[UA_tracts.area > 0]\n",
    "    return UA_tracts.reset_index()\n",
    "\n",
    "def calculate_prop_vectors(city_tracts, numerator_cols: list, denominator_col: str):\n",
    "    prop_cols = city_tracts[numerator_cols].apply(lambda x: x/city_tracts[denominator_col])\n",
    "\n",
    "    prop_cols[\"other\"] = np.max(1 - prop_cols.sum(axis=1), 0)\n",
    "    row_totals = prop_cols.sum(axis=1)\n",
    "    prop_cols = prop_cols.divide(row_totals, axis=0)\n",
    "    \n",
    "    prop_df = pd.DataFrame({\"GEOID\": city_tracts[\"GEOID\"], \"pdf\": prop_cols.apply(lambda x: x.to_list(), axis=1)})\n",
    "    return prop_df\n",
    "def bb_area(x1, y1, x2, y2):\n",
    "    return (x2 - x1) * (y2 - y1)\n",
    "\n",
    "# https://www.matecdev.com/posts/random-points-in-polygon.html\n",
    "def gen_random_points_in_bb(polygon: Polygon, num: int):\n",
    "    minx, miny, maxx, maxy = polygon.bounds\n",
    "    # print(polygon.bounds)\n",
    "    return [Point(element) for element in list(zip(np.random.uniform( minx, maxx, num ), np.random.uniform( miny, maxy, num )))]\n",
    "\n",
    "def gen_random_points_in_poly(polygon: Polygon, num: int, GEOID: str):\n",
    "    area = polygon.area\n",
    "    # print(polygon.bounds)\n",
    "    _bb_area = bb_area(*polygon.bounds)\n",
    "    # mul by 1.5 to make that most of the time, enough points land inside the geometry\n",
    "    num_in_bb = int(1.5 * num * (_bb_area / area))\n",
    "    bb_points = gen_random_points_in_bb(polygon, num_in_bb)\n",
    "\n",
    "    points_list = list(filter(lambda point: polygon.contains(point), bb_points))[:num]\n",
    "    points_gdf = gpd.GeoDataFrame(geometry = points_list)\n",
    "    points_gdf[\"GEOID\"] = GEOID\n",
    "    return points_gdf\n",
    "\n",
    "def create_points_for_city(city_tracts, pop_per_point):\n",
    "    # Slightly awkward iteration bc I was having trouble getting apply to do what I wanted\n",
    "    gdfs = []\n",
    "    for i in range(len(city_tracts.index)):\n",
    "        points_per = int(city_tracts[\"total_pop\"][i] // pop_per_point)\n",
    "        temp_gdf = gen_random_points_in_poly(city_tracts[\"geometry\"][i], points_per, city_tracts[\"GEOID\"][i])\n",
    "        gdfs.append(temp_gdf)\n",
    "\n",
    "    gdf = gpd.GeoDataFrame(pd.concat(gdfs))\n",
    "    return gdf\n",
    "\n",
    "def gen_dot_density(polygon:Polygon, total_pop:int, pop_per_point:int, pdf: np.array, labels: list):\n",
    "    points = gen_random_points_in_poly(polygon, int(total_pop // pop_per_point))\n",
    "    return [\n",
    "        {\n",
    "            \"ethnicity\": np.random.choice(labels, p=pdf),\n",
    "        \"x\": point.x,\n",
    "        \"y\": point.y} for point in points]\n",
    "\n",
    "def augment_points_with_labels(points: gpd.GeoDataFrame, prop_df: pd.DataFrame, name: str, labels: list):\n",
    "\n",
    "    points_prop = points.merge(prop_df)\n",
    "    points_prop[name] = points_prop.apply(lambda row: np.random.choice(labels, p=row[\"pdf\"]), axis = 1)\n",
    "    points_prop = points_prop.drop(\"pdf\", axis = 1)\n",
    "    \n",
    "    return points_prop\n",
    "\n",
    "def get_ppp(pop):\n",
    "    if pop < 500000:\n",
    "        return 25\n",
    "    elif pop < 1000000:\n",
    "        return 50\n",
    "    elif pop < 2000000:\n",
    "        return 100\n",
    "    else:\n",
    "        return 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T15:03:29.575480Z",
     "iopub.status.busy": "2023-06-30T15:03:29.575088Z",
     "iopub.status.idle": "2023-06-30T15:03:29.594914Z",
     "shell.execute_reply": "2023-06-30T15:03:29.593985Z",
     "shell.execute_reply.started": "2023-06-30T15:03:29.575453Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from geopandas.geodataframe import GeoDataFrame\n",
    "\n",
    "@dataclass\n",
    "class DotDensityConfiguration:\n",
    "    city_name: str\n",
    "    ppp: int\n",
    "    output_dir_prefix: str\n",
    "    crs: int\n",
    "    \n",
    "@dataclass\n",
    "class DotDensityRenderOutput:\n",
    "    config: DotDensityConfiguration\n",
    "    city_bounds: GeoDataFrame\n",
    "    rmp_buffers: GeoDataFrame\n",
    "    dot_density: GeoDataFrame\n",
    "    ppp: int\n",
    "\n",
    "def render_city_data(config: DotDensityConfiguration) -> DotDensityRenderOutput:\n",
    "    city = get_UA_tracts(config.city_name, gdf_tract, gdf_urban_all)\n",
    "    city_points = create_points_for_city(city, config.ppp)\n",
    "    city_race_props = calculate_prop_vectors(city, [\"white_pop\", \"black_pop\", \"asian_pop\", \"hispanic_pop\"], \"total_pop\")\n",
    "    labels= [\"White\", \"Black\", \"Asian\", \"Hispanic/Latino\", \"Another race\"]\n",
    "    race_points = augment_points_with_labels(city_points, city_race_props, \"race\", labels)\n",
    "    city_pov_props = calculate_prop_vectors(city, [\"pop_in_poverty\"], \"total_pop\")\n",
    "    labels = [\"Below poverty line\", \"Above poverty line\"]\n",
    "    rmp_buffers = get_rmp_zones(city, RMP_facilities, 1)\n",
    "    final_points = augment_points_with_labels(race_points, city_pov_props, \"poverty\", labels)\n",
    "    final_points = final_points.set_geometry(\"geometry\").set_crs(2263)\n",
    "    water = get_water(city, threshold=10000000)\n",
    "    city_bounds = gdf_urban_all[gdf_urban_all[\"UA_NAME\"] == config.city_name]\n",
    "    \n",
    "    return DotDensityRenderOutput(\n",
    "        config=config,\n",
    "        city_bounds=city_bounds.to_crs(config.crs),\n",
    "        rmp_buffers=rmp_buffers.to_crs(config.crs),\n",
    "        dot_density=final_points.to_crs(config.crs),\n",
    "        ppp=config.ppp)\n",
    "\n",
    "def export_viz_to_json_data(path: pathlib.Path, render_output: DotDensityRenderOutput):\n",
    "    full_path = path / render_output.config.output_dir_prefix\n",
    "    print(full_path)\n",
    "    full_path.mkdir(parents=True, exist_ok=True)\n",
    "    render_output.city_bounds.to_file(str(full_path / \"city_boundaries.geojson\"), DRIVER=\"json\")\n",
    "    render_output.rmp_buffers.to_file(str(full_path / \"rmp_buffers.geojson\"), DRIVER=\"json\")\n",
    "    render_output.dot_density.to_file(str(full_path / \"dot_density.geojson\"), DRIVER=\"json\")\n",
    "    pd.DataFrame([render_output.ppp], columns = [\"ppp\"]).to_csv(str(full_path / \"ppp.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_cities = final_UAs.UA_NAME.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_name(city):\n",
    "    city = city.split(',')[0]\n",
    "    return ''.join(letter for letter in city if letter.isalpha()).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stlouis'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_name(\"St. Louis, MO--IL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Port Arthur, TX\n",
      "25\n",
      "data/viz/portarthur\n",
      "Beaumont, TX\n",
      "25\n",
      "data/viz/beaumont\n",
      "Phoenix West--Goodyear--Avondale, AZ\n",
      "25\n",
      "data/viz/phoenixwestgoodyearavondale\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/canyonfoot/Documents/python_proj/EPA-Hack-Day-Analysis/.venv/lib/python3.10/site-packages/geopandas/io/file.py:572: UserWarning: You are attempting to write an empty DataFrame to file. For some drivers, this operation may fail.\n",
      "  _to_file_fiona(df, filename, driver, schema, crs, mode, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Austin, TX\n",
      "100\n",
      "data/viz/austin\n",
      "Los Angeles--Long Beach--Anaheim, CA\n",
      "150\n",
      "San Diego, CA\n",
      "150\n",
      "data/viz/sandiego\n",
      "Riverside--San Bernardino, CA\n",
      "150\n",
      "data/viz/riversidesanbernardino\n",
      "Salt Lake City, UT\n",
      "100\n",
      "data/viz/saltlakecity\n",
      "Bakersfield, CA\n",
      "50\n",
      "data/viz/bakersfield\n",
      "McAllen, TX\n",
      "50\n",
      "data/viz/mcallen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/canyonfoot/Documents/python_proj/EPA-Hack-Day-Analysis/.venv/lib/python3.10/site-packages/geopandas/io/file.py:572: UserWarning: You are attempting to write an empty DataFrame to file. For some drivers, this operation may fail.\n",
      "  _to_file_fiona(df, filename, driver, schema, crs, mode, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longview, TX\n",
      "25\n",
      "data/viz/longview\n",
      "Phoenix--Mesa--Scottsdale, AZ\n",
      "150\n",
      "data/viz/phoenixmesascottsdale\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/canyonfoot/Documents/python_proj/EPA-Hack-Day-Analysis/.venv/lib/python3.10/site-packages/geopandas/io/file.py:572: UserWarning: You are attempting to write an empty DataFrame to file. For some drivers, this operation may fail.\n",
      "  _to_file_fiona(df, filename, driver, schema, crs, mode, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oxnard--San Buenaventura (Ventura), CA\n",
      "25\n",
      "data/viz/oxnardsanbuenaventuraventura\n",
      "Yuma, AZ--CA\n",
      "25\n",
      "data/viz/yuma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/canyonfoot/Documents/python_proj/EPA-Hack-Day-Analysis/.venv/lib/python3.10/site-packages/geopandas/io/file.py:572: UserWarning: You are attempting to write an empty DataFrame to file. For some drivers, this operation may fail.\n",
      "  _to_file_fiona(df, filename, driver, schema, crs, mode, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yakima, WA\n",
      "25\n",
      "data/viz/yakima\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/canyonfoot/Documents/python_proj/EPA-Hack-Day-Analysis/.venv/lib/python3.10/site-packages/geopandas/io/file.py:572: UserWarning: You are attempting to write an empty DataFrame to file. For some drivers, this operation may fail.\n",
      "  _to_file_fiona(df, filename, driver, schema, crs, mode, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kennewick--Richland--Pasco, WA\n",
      "25\n",
      "data/viz/kennewickrichlandpasco\n",
      "Orange, TX\n",
      "25\n",
      "data/viz/orange\n",
      "Denver--Aurora, CO\n",
      "150\n",
      "data/viz/denveraurora\n",
      "Ogden--Layton, UT\n",
      "50\n",
      "data/viz/ogdenlayton\n",
      "Seattle--Tacoma, WA\n",
      "150\n",
      "data/viz/seattletacoma\n",
      "Baton Rouge, LA\n",
      "50\n",
      "data/viz/batonrouge\n",
      "New Orleans, LA\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "for city in list_of_cities:\n",
    "    try:\n",
    "        prefix = process_name(city)\n",
    "        city_pop = get_UA_tracts(city, gdf_tract, gdf_urban_all).total_pop.sum()\n",
    "        ppp = get_ppp(city_pop)\n",
    "        print(city)\n",
    "        print(ppp)\n",
    "        config = DotDensityConfiguration(city_name=city, ppp=ppp, output_dir_prefix=prefix, crs=4326)\n",
    "        result = render_city_data(config)\n",
    "        export_viz_to_json_data(pathlib.Path(\"data/viz/\"), result)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/data/viz')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathlib.Path(\"/data/viz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Beaumont, TX'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_cities[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "canyon_nest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
